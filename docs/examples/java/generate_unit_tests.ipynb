{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install ollama"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee51e198aaebcd9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using CLDK to generate JUnit tests\n",
    "\n",
    "In this tutorial, we will use CLDK to generate a JUnit test for all the methods in a Java Application.\n",
    "\n",
    "By the end of this tutorial, you will have a JUnit test for all the methods in a Java application. You'll be able to explore some of the benefits of using CLDK to perform fast and easy program analysis and build a LLM-based test generator.\n",
    "\n",
    "You will learn how to do the following:\n",
    "\n",
    "<ol>\n",
    "<li> Create a new instance of the CLDK class.\n",
    "<li> Create an analysis object over the Java application.\n",
    "<li> Iterate over all the files in the project.\n",
    "<li> Iterate over all the classes in the file.\n",
    "<li> Iterate over all the methods in the class.\n",
    "<li> Get the code body of the method.\n",
    "<li> Initialize the treesitter utils for the class file content.\n",
    "<li> Sanitize the class for analysis.\n",
    "</ol>\n",
    "Next, we will write a couple of helper methods to:\n",
    "\n",
    "<ol>\n",
    "<li> Format the instruction for the given focal method and class.\n",
    "<li> Prompts the local model on Ollama.\n",
    "<li> Prints the instruction and LLM output.\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "428dbbfa206f5417"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prequisites\n",
    "\n",
    "Before we get started, let's make sure you have the following installed:\n",
    "\n",
    "<ol>\n",
    "<li> Python 3.11 or later\n",
    "<li> Ollama 0.3.4 or later\n",
    "</ol>\n",
    "We will use ollama to spin up a local granite model that will act as our LLM for this turorial."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f619a9379b9dd006"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prerequisite 1: Install ollama\n",
    "\n",
    "If you don't have ollama installed, please download and install it from here: [Ollama](https://ollama.com/download).\n",
    "Once you have ollama, start the server and make sure it is running.\n",
    "If you're on MacOS, Linux, or WSL, you can check to make sure the server is running by running the following command:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3485879a7733bcba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "systemctl status ollama"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f67be6c8c024e12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If not, you may have to start the server manually. You can do this by running the following command:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "273e60ca598e0a53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "systemctl start ollama"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc6877ce338e9102"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once ollama is up and running, you can download the latest version of the Granite 8b Instruct model by running the following command:\n",
    "\n",
    "There are other granite versions available, but for this tutorial, we will use the Granite 8b Instruct model. You if prefer to use a different version, you can replace `8b-instruct` with any of the other [versions](https://ollama.com/library/granite-code/tags)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c024dc7ec2869a72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ollama pull granite-code:8b-instruct"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ad0e8ac33c7108e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's make sure the model is downloaded by running the following command:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f9946fdc5e2025"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ollama run granite-code:8b-instruct \\\"Write a python function to print 'Hello, World!'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3410ce4d0afa788"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prerequisite 3: Install ollama Python SDK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8c0224c3c4ecf4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pip install ollama"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5539b5251aee5642"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prerequisite 4: Install CLDK\n",
    "CLDK is avaliable on github at github.com/IBM/codellm-devkit.git. You can install it by running the following command:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cea573e625257581"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pip install git+https://github.com/IBM/codellm-devkit.git"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeb38b312427329d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Get the sample Java application\n",
    "For this tutorial, we will use apache commons cli. You can download the source code to a temporary directory by running the following command:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca7682c71d844b68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wget https://github.com/apache/commons-cli/archive/refs/tags/rel/commons-cli-1.7.0.zip -O /tmp/commons-cli-1.7.0.zip && unzip -o /tmp/commons-cli-1.7.0.zip -d /tmp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4d08ca64b9dbccb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The project will now be extracted to `/tmp/commons-cli-rel-commons-cli-1.7.0`. We'll remove these files later, so don't worry about the location."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51d30f3eb726afc0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building a JUnit test generator using CLDK and Granite Code Instruct Model\n",
    "Now that we have all the prerequisites installed, let's start building a JUnit test generator using CLDK and the Granite Code Instruct Model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98e69eb0bccedfc9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating unit tests for code is a very tedious task and often takes a significant effort from the developers to write good test cases. There are various tools that are available for automated test generation, such as EvoSuite, which uses evolutionary algorithms to generate test cases. However, the test cases that are being generated are not natural and often developers do not prefer to add them to their test suite. Whereas Large Language Models (LLM) being trained with developer-written code it has a better affinity towards generating more natural code--more readable, maintainable code. In this excercise, we will show we can leverage LLMs to generate test cases with the help of CLDK. \n",
    "\n",
    "For simplicity, we will cover certain aspects of test generation and provide some context information to LLM for better quality of test cases. In this exercise, we will generate a unit test for a non-private method from a Java class and provide the focal method body and the signature of all the constructors of the class so that LLM can understand how to create an object of the focal class during the setup phase of the tests. Also, we will ask LLMs to generate ```N``` number of test cases, where ```N``` is the cyclomatic complexity of the focal method. The intuition is that one test may not be sufficient for covering fairly complex methods, and a cyclomatic complexity score can provide some guidance towards that. \n",
    "\n",
    "(Step 1) First, we will import all the necessary libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5856baff4aa64ed7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ollama\n",
    "from cldk import CLDK\n",
    "from cldk.analysis import AnalysisLevel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3d2498ae092fcc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Step 2) Second, we will form the prompt for the model, which will include all the constructor signarures, and the body of the focal method."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67eb24b29826d730"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def format_inst(focal_method_body, focal_method, focal_class, constructor_signatures, cyclomatic_complexity, language):\n",
    "    \"\"\"\n",
    "    Format the instruction for the given focal method and class.\n",
    "    \"\"\"\n",
    "    inst = f\"Question: Can you generate {cyclomatic_complexity} unit tests for the method `{focal_method}` in the class `{focal_class}` below?\\n\"\n",
    "\n",
    "    inst += \"\\n\"\n",
    "    inst += f\"```{language}\\n\"\n",
    "    inst += \"```\\n\"\n",
    "    inst += \"public class {focal_class} {\"\n",
    "    inst += f\"<|constructors|>\\n{constructor_signatures}\\n<|constructors|>\\n\"\n",
    "    inst += f\"<|focal method|>\\n {focal_method_body} \\n <|focal method|>\\n\" \n",
    "    inst += \"}\"\n",
    "    inst += \"```\\n\"\n",
    "    inst += \"Answer:\\n\"\n",
    "    return inst"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7bc9bbaa917df24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Step 3) Third, use ollama to call LLM (in case Granite 8b)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae9ceb150f5efa92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prompt_ollama(message: str, model_id: str = \"granite-code:20b-instruct\") -> str:\n",
    "    \"\"\"Prompt local model on Ollama\"\"\"\n",
    "    response_object = ollama.generate(model=model_id, prompt=message)\n",
    "    return response_object[\"response\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52634feae7374599"
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Step 4) Fourth, collect all the information needed for each method. In this process, we go through all the classes in the application, and then for each class, we collect the signature of all the constructors. If there is no constructor present, we add the signature of the default constructor. Then, we go through all the non-private methods of the class and formulate the prompt using the constructor and the method information. Finally, we use the prompt to call LLM and get the final output."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "308c3325116b87d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a new instance of the CLDK class\n",
    "cldk = CLDK(language=\"java\")\n",
    "# Create an analysis object over the java application. Provide the application path.\n",
    "analysis = cldk.analysis(project_path=\"/tmp/commons-cli-rel-commons-cli-1.7.0\", analysis_level=AnalysisLevel.symbol_table)\n",
    "# Go through all the classes in the application\n",
    "for class_name in analysis.get_classes():\n",
    "    class_details  = analysis.get_class(qualified_class_name=class_name)\n",
    "    # Generate test cases for non-interface and non-abstract classes\n",
    "    if not class_details.is_interface and 'abstract' not in class_details.modifiers:\n",
    "        # Get all constructor signatures\n",
    "        constructor_signatures = ''\n",
    "        for method in analysis.get_methods_in_class(qualified_class_name=class_name):\n",
    "            method_details = analysis.get_method(qualified_class_name=class_name, qualified_method_name=method)\n",
    "            if method_details.is_constructor:\n",
    "                constructor_signatures += method_details.signature + '\\n'\n",
    "        # If no constructor present, then add the signature of the default constructor\n",
    "        if constructor_signatures=='':\n",
    "            constructor_signatures = f'public {class_name} ()'\n",
    "        # Go through all the methods in the class\n",
    "        for method in analysis.get_methods_in_class(qualified_class_name=class_name):\n",
    "            # Get the method details\n",
    "            method_details = analysis.get_method(qualified_class_name=class_name, qualified_method_name=method)\n",
    "            # Generate test cases for non-private methods\n",
    "            if 'private' not in method_details.modifiers and not method_details.is_constructor:\n",
    "                # Gather all the information needed for the prompt, which are focal method body, focal method name, focal class name, constructor signature, and cyclomatic complexity\n",
    "                prompt = format_inst(focal_method_body=method_details.code,\n",
    "                                     focal_method=method,\n",
    "                                     focal_class=class_name,\n",
    "                                     constructor_signatures=constructor_signatures,\n",
    "                                     cyclomatic_complexity=method_details.cyclomatic_complexity)\n",
    "                # Prompt the local model on Ollama\n",
    "                llm_output = prompt_ollama(\n",
    "                    message=prompt,\n",
    "                    model_id=\"granite-code:20b-instruct\",\n",
    "                )\n",
    "        \n",
    "                # Print the instruction and LLM output\n",
    "                print(f\"Instruction:\\n{prompt}\")\n",
    "                print(f\"LLM Output:\\n{llm_output}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65c9558e4de65a52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
