{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d05bbe28e62687",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Using CLDK to explain Java methods\n",
    "\n",
    "In this tutorial, we will use CLDK to explain or generate code summary for a Java method. You'll explore some of the benefits of using CLDK to perform quick and easy program analysis and build an LLM-based code summarizer. By the end of this tutorial, you will have implemented such a tool and generated code summary for a Java method.\n",
    "\n",
    "Specifically, you will learn how to perform the following tasks on a Java application to create LLM prompts for code summarization:\n",
    "\n",
    "1. Create a new instance of the CLDK class.\n",
    "2. Create an analysis object for the target Java application.\n",
    "3. Iterate over all files in the application.\n",
    "4. Iterate over all classes in a file.\n",
    "5. Initialize treesitter utils for the class content.\n",
    "6. Iterate over all methods in a class.\n",
    "7. Get the code body of a method.\n",
    "8. Sanitize the class for prompting the LLM.\n",
    "\n",
    "We will write a couple of helper methods to (1) format the LLM instruction for summarizing a given target method and (2) prompt the LLM via Ollama. We will then use CLDK to go through an application and generate the summary for the target method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92896c8ce12b0e9e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prequisites\n",
    "\n",
    "Before we get started, let's make sure you have the following installed:\n",
    "\n",
    "1. Python 3.11 or later (you can use [pyenv](https://github.com/pyenv/pyenv) to install Python)\n",
    "2. Java 11 or later (you can use [SDKMAN!](https://sdkman.io) to instal Java)\n",
    "3. Ollama 0.3.4 or later (you can get Ollama here: [Ollama download](https://ollama.com/download))\n",
    "\n",
    "We will use Ollama to spin up a local [Granite code model](https://ollama.com/library/granite-code), which will serve as our LLM for this turorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb1e1227191e3b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Download Granite code model\n",
    "\n",
    "After starting the Ollama server, please download the latest version of the Granite code 8b-instruct model by running the following command. There are other Granite code models available, but for this tutorial, we will use Granite code 8b-instruct. If you prefer to use a different Granite code model, you can replace `8b-instruct` with the tag of another version (see [Granite code tags](https://ollama.com/library/granite-code/tags))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e7184",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ollama pull granite-code:8b-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1ca5b",
   "metadata": {},
   "source": [
    " Let's make sure the model is downloaded by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff900382e86a18e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ollama run granite-code:8b-instruct \\\"Write a python function to print 'Hello, World!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531205b489bbec73",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Install Ollama Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a749932a800c9d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42dbd286b3f7a6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Install CLDK\n",
    "CLDK is avaliable at https://github.com/IBM/codellm-devkit. You can install it by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e212f20a489d6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/IBM/codellm-devkit.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ec5b9c837898f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Get the sample Java application\n",
    "For this tutorial, we will use [Apache Commons CLI](https://github.com/apache/commons-cli) as the sample Java application. You can download the source code to a temporary directory by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196e58b3ce90c34",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://github.com/apache/commons-cli/archive/refs/tags/rel/commons-cli-1.7.0.zip -O /tmp/commons-cli-1.7.0.zip && unzip -o /tmp/commons-cli-1.7.0.zip -d /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e875e7ce6db504",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The project will now be extracted to `/tmp/commons-cli-rel-commons-cli-1.7.0`.\n",
    "<!-- We'll remove these files later, so don't worry about the location. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad70b81e8957fc0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate code summary\n",
    "\n",
    "Code summarization or code explanation is the task of converting code written in a programming language to natural language. It has several benefits, such as understanding code without looking at its intrinsic details, documenting code for better maintenance, etc. To perform code summarization, one needs to understand the basic details of code implementation, and use that knowledge to generate the summary using various AI-based approaches. In this tutorial, we will use LLMs, specifically Granite code 8b-instruct. We will show how a developer can easily use CLDK to analyze code by calling various APIs without having to implement such analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15555404790e1411",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 1: Add the neccessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e5de7e5c68020",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "from cldk import CLDK\n",
    "from cldk.analysis import AnalysisLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc4ee9a6d27acc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 2: Define a function for creating the LLM prompt, which instructs the LLM to summarize a Java method and includes relevant code for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23523c71636727",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_inst(code, focal_method, focal_class, language):\n",
    "    \"\"\"\n",
    "    Format the instruction for the given focal method and class.\n",
    "    \"\"\"\n",
    "    inst = f\"Question: Can you write a brief summary for the method `{focal_method}` in the class `{focal_class}` below?\\n\"\n",
    "\n",
    "    inst += \"\\n\"\n",
    "    inst += f\"```{language}\\n\"\n",
    "    inst += code\n",
    "    inst += \"```\" if code.endswith(\"\\n\") else \"\\n```\"\n",
    "    inst += \"\\n\"\n",
    "    return inst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e9cb4e4f00b25c",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd8439be222b5caa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 3: Define a function to call the LLM (in this case, Granite code 8b-instruct) using Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62807e0cbf985ae6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prompt_ollama(message: str, model_id: str = \"granite-code:8b-instruct\") -> str:\n",
    "    \"\"\"Prompt local model on Ollama\"\"\"\n",
    "    response_object = ollama.generate(model=model_id, prompt=message, options={\"temperature\":0.2})\n",
    "    return response_object[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022e86e38e12767",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 4: Create an instance of CLDK and provide the programming language of the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c8bbe4e3244f60",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an instance of CLDK for Java analysis\n",
    "cldk = CLDK(language=\"java\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd4a6e5d5cb0c5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 5: Select the analysis engine and analysis level. CLDK uses different analysis engines---[CodeAnalyzer](https://github.com/IBM/codenet-minerva-code-analyzer) (built over [WALA](https://github.com/wala/WALA) and [JavaParser](https://github.com/javaparser/javaparser)), [Treesitter](https://tree-sitter.github.io/tree-sitter/), and [CodeQL](https://codeql.github.com/) (future)---with CodeAnalyzer being the default analysis engine. CLDK supports different analysis levels: (1) symbol table, (2) call graph, (3) program dependency graph, and (4) system dependency graph. The analysis level can be selected using the `AnalysisLevel` enumerated type. For this example, we select the symbol-table analysis level, with CodeAnalyzer as the default analysis engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd09f5e77d4a68a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an analysis object over the java application\n",
    "analysis = cldk.analysis(project_path=\"/tmp/commons-cli-rel-commons-cli-1.7.0\", analysis_level=AnalysisLevel.symbol_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148325e92781e13",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 6: Iterate over all the class files and create the prompt. In this case, we want to provide a sanitized Java class in the prompt, containing only the relevant information for summarizing the target method. To illustrate, consider the floowing class:\n",
    "\n",
    "```java\n",
    "package com.ibm.org;\n",
    "import A.B.C.D;\n",
    "...\n",
    "public class Foo {\n",
    " // code comment\n",
    " public void bar(){ \n",
    "    int a;\n",
    "    a = baz();\n",
    "    // do something\n",
    "    }\n",
    " private int baz()\n",
    " {\n",
    "    // do something\n",
    " }\n",
    " public String dummy (String a)\n",
    " {\n",
    "    // do somthing\n",
    " }   \n",
    "```\n",
    "Let's say we want to generate a summary for method `bar`. To understand what it does, we add the callees of this method in the prompt, which in this case includes `baz`. We remove the other methods, imports, comments, etc. All of this can be achieved with a single call to CLDK's `sanitize_focal_class` API. In this process, we also use Treesitter to analyze the code.  After creating the sanitized code, we call the previously defined `format_inst` method to create the LLM prompt and pass the prompt to `prompt_ollama` to generate the method summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462ef7dceae367ad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For simplicity, we run the code summarization for a single class and method (this filter can be removed to run this code over the entire application)\n",
    "target_class = \"org.apache.commons.cli.GnuParser\"\n",
    "target_method = \"flatten(Options, String[], boolean)\"\n",
    "\n",
    "# Iterate over all classes in the application\n",
    "for class_name in analysis.get_classes():\n",
    "    if class_name == target_class:\n",
    "        class_file_path = analysis.get_java_file(qualified_class_name=class_name)\n",
    "\n",
    "        # Read code for the class\n",
    "        with open(class_file_path, 'r') as f:\n",
    "            code_body = f.read()\n",
    "\n",
    "        # Initialize treesitter utils for the class file content\n",
    "        tree_sitter_utils = cldk.tree_sitter_utils(source_code=code_body)\n",
    "                \n",
    "        # Iterate over all methods in class\n",
    "        for method in analysis.get_methods_in_class(qualified_class_name=class_name):\n",
    "            if method == target_method:\n",
    "        \n",
    "                # Get all the method details\n",
    "                method_details = analysis.get_method(qualified_class_name=class_name,\n",
    "                                                     qualified_method_name=method)\n",
    "                \n",
    "                # Sanitize the class for analysis with respect to the target method\n",
    "                sanitized_class = tree_sitter_utils.sanitize_focal_class(method_details.declaration)\n",
    "        \n",
    "                # Format the instruction for the given target method and class\n",
    "                instruction = format_inst(\n",
    "                    code=sanitized_class,\n",
    "                    focal_method=method_details.declaration,\n",
    "                    focal_class=class_name.split('.')[-1],\n",
    "                    language=\"java\"\n",
    "                )\n",
    "    \n",
    "                print(f\"Instruction:\\n{instruction}\\n\")\n",
    "                print(f\"Generating code summary . . .\\n\")\n",
    "                \n",
    "                # Prompt the local model on Ollama\n",
    "                llm_output = prompt_ollama(\n",
    "                    message=instruction\n",
    "                )\n",
    "        \n",
    "                # Print the LLM output\n",
    "                print(f\"LLM Output:\\n{llm_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
