{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428dbbfa206f5417",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Using CLDK to generate JUnit tests\n",
    "\n",
    "In this tutorial, we will use CLDK to implement a simple unit test generator for Java. You'll explore some of the benefits of using CLDK to perform quick and easy program analysis and build an LLM-based test generator. By the end of this tutorial, you will have implemented such a tool and generated a JUnit test case for a Java application.\n",
    "\n",
    "Specifically, you will learn how to perform the following tasks on the application under test to create LLM prompts for test generation:\n",
    "\n",
    "1. Create a new instance of the CLDK class.\n",
    "2. Create an analysis object for the Java application under test.\n",
    "3. Iterate over all files in the application.\n",
    "4. Iterate over all classes in a file.\n",
    "5. Iterate over all methods in a class.\n",
    "6. Get the code body of a method.\n",
    "7. Get the constructors of a class.\n",
    "<!-- 7. Initialize treesitter utils for the class file content.\n",
    "8. Sanitize the class for analysis. -->\n",
    "\n",
    "We will write a couple of helper methods to (1) format the LLM instruction for generating test cases for a given focal method (i.e., method under test) and (2) prompt the LLM via Ollama. We will then use CLDK to go through an application and generate unit test cases for the target method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619a9379b9dd006",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prequisites\n",
    "\n",
    "Before we get started, let's make sure you have the following installed:\n",
    "\n",
    "1. Python 3.11 or later (you can use [pyenv](https://github.com/pyenv/pyenv) to install Python)\n",
    "2. Java 11 or later (you can use [SDKMAN!](https://sdkman.io) to instal Java)\n",
    "3. Ollama 0.3.4 or later (you can get Ollama here: [Ollama download](https://ollama.com/download))\n",
    "\n",
    "We will use Ollama to spin up a local [Granite code model](https://ollama.com/library/granite-code), which will serve as our LLM for this turorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485879a7733bcba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Download Granite code model\n",
    "\n",
    "After starting the Ollama server, please download the latest version of the Granite code 8b-instruct model by running the following command. There are other Granite code models available, but for this tutorial, we will use Granite code 8b-instruct. If you prefer to use a different Granite code model, you can replace `8b-instruct` with the tag of another version (see [Granite code tags](https://ollama.com/library/granite-code/tags))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f2b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ollama pull granite-code:8b-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5bbfa",
   "metadata": {},
   "source": [
    " Let's make sure the model is downloaded by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3410ce4d0afa788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T23:49:03.488152Z",
     "start_time": "2024-08-28T23:49:03.424389Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ollama run granite-code:8b-instruct \\\"Write a python function to print 'Hello, World!'\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0224c3c4ecf4d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Install Ollama Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539b5251aee5642",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea573e625257581",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Install CLDK\n",
    "CLDK is avaliable at https://github.com/IBM/codellm-devkit. You can install it by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb38b312427329d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/IBM/codellm-devkit.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7682c71d844b68",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Get the sample Java application\n",
    "For this tutorial, we will use [Apache Commons CLI](https://github.com/apache/commons-cli) as the Java application under test. You can download the source code to a temporary directory by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d08ca64b9dbccb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://github.com/apache/commons-cli/archive/refs/tags/rel/commons-cli-1.7.0.zip -O /tmp/commons-cli-1.7.0.zip && unzip -o /tmp/commons-cli-1.7.0.zip -d /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d30f3eb726afc0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The project will be extracted to `/tmp/commons-cli-rel-commons-cli-1.7.0`.\n",
    "<!-- We'll remove these files later, so don't worry about the location. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e69eb0bccedfc9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Build a JUnit test generator using CLDK and Granite Code Model\n",
    "\n",
    "Now that we have all the prerequisites installed, let's start building a JUnit test generator using CLDK and the Granite Code Instruct Model.\n",
    "\n",
    "Generating unit tests for code is a tedious task and developers often have to put in significant effort in writing good test cases. There are various tools available for automated test generation, such as EvoSuite, which uses evolutionary algorithms to generate unit test cases for Java. However, the generated test cases are not natural and often developers do not prefer to add them to their test suites. LLMs, having been trained with developer-written code, have a better affinity towards generating more natural code---code that is more readable, comprehensible, and maintainable. In this excercise, we will show how we can leverage LLMs to generate test cases with the help of CLDK. \n",
    "\n",
    "For simplicity, we will cover certain aspects of test generation and provide some context information to the LLM to help it create usable test cases. In this exercise, we will generate a unit test for a non-private method from a Java class and provide the focal method body and the signature of all the constructors of the class so that LLM can understand how to create an object of the focal class during the setup phase of the tests.\n",
    "<!-- Also, we will ask LLMs to generate ```N``` number of test cases, where ```N``` is the cyclomatic complexity of the focal method. The intuition is that one test may not be sufficient for covering fairly complex methods, and a cyclomatic complexity score can provide some guidance towards that.  -->\n",
    "\n",
    "Step 1: Import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2498ae092fcc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "from cldk import CLDK\n",
    "from cldk.analysis import AnalysisLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb24b29826d730",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 2: Define a function for creating the LLM prompt, which instructs the LLM to generate unit tests cases and includes signatures of relevant constructors and the body of the focal method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc9bbaa917df24",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_inst(focal_method_body, focal_method, focal_class, constructor_signatures, language):\n",
    "    \"\"\"\n",
    "    Format the LLM instruction for the given focal method and class.\n",
    "    \"\"\"\n",
    "    inst = f\"Question: Can you generate junit tests with @Test annotation for the method `{focal_method}` in the class `{focal_class}` below. Only generate the test and no description.\\n\"\n",
    "    inst += 'Use the constructor signatures to form the object if the method is not static. Generate the code under ``` code block.'\n",
    "    inst += \"\\n\"\n",
    "    inst += f\"```{language}\\n\"\n",
    "    inst += f\"public class {focal_class} \" + \"{\\n\"\n",
    "    inst += f\"{constructor_signatures}\\n\"\n",
    "    inst += f\"{focal_method_body} \\n\" \n",
    "    inst += \"}\"\n",
    "    inst += \"```\\n\"\n",
    "    inst += \"Answer:\\n\"\n",
    "    return inst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ceb150f5efa92",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 3: Define a function to call the LLM (in this case, Granite code 8b-instruct) using Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52634feae7374599",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prompt_ollama(message: str, model_id: str = \"granite-code:8b-instruct\") -> str:\n",
    "    \"\"\"Prompt local model on Ollama\"\"\"\n",
    "    response_object = ollama.generate(model=model_id, prompt=message, options={\"temperature\":0.2})\n",
    "    return response_object[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c3325116b87d4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 4: Collect the relevant information for the focal method and prompt the LLM. To do this, we go through all the classes in the application, and for each class, we collect the signatures of its constructors. If a class has no constructors, we add the signature of the default constructor. Then, we go through each non-private method of the class and formulate the prompt using the constructor and the method information. Finally, we use the prompt to call LLM to generate test cases and get the LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9558e4de65a52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an instance of CLDK for Java analysis\n",
    "cldk = CLDK(language=\"java\")\n",
    "\n",
    "# Create an analysis object for the Java application. Provide the application path.\n",
    "analysis = cldk.analysis(project_path=\"/tmp/commons-cli-rel-commons-cli-1.7.0\", analysis_level=AnalysisLevel.symbol_table)\n",
    "\n",
    "# For simplicity, we run the test generation on a single focal class and method (this filter can be removed to run this code over the entire application)\n",
    "focal_class = \"org.apache.commons.cli.GnuParser\"\n",
    "focal_method = \"flatten(Options, String[], boolean)\"\n",
    "\n",
    "# Go through all the classes in the application\n",
    "for class_name in analysis.get_classes():\n",
    "\n",
    "    if class_name == focal_class:\n",
    "        class_details  = analysis.get_class(qualified_class_name=class_name)\n",
    "        focal_class_name = class_name.split(\".\")[-1]\n",
    "\n",
    "        # Generate test cases for non-interface and non-abstract classes\n",
    "        if not class_details.is_interface and \"abstract\" not in class_details.modifiers:\n",
    "            \n",
    "            # Get all constructor signatures\n",
    "            constructor_signatures = \"\"\n",
    "            \n",
    "            for method in analysis.get_methods_in_class(qualified_class_name=class_name):\n",
    "                method_details = analysis.get_method(qualified_class_name=class_name, qualified_method_name=method)\n",
    "                \n",
    "                if method_details.is_constructor:\n",
    "                    constructor_signatures += method_details.signature + '\\n'\n",
    "            \n",
    "            # If no constructor present, then add the signature of the default constructor\n",
    "            if constructor_signatures == \"\":\n",
    "                constructor_signatures = f\"public {focal_class_name}() \" + \"{}\"\n",
    "            \n",
    "            # Go through all the methods in the class\n",
    "            for method in analysis.get_methods_in_class(qualified_class_name=class_name):\n",
    "                \n",
    "                if method == focal_method:\n",
    "                    # Get the method details\n",
    "                    method_details = analysis.get_method(qualified_class_name=class_name, qualified_method_name=method)\n",
    "                    \n",
    "                    # Generate test cases for non-private methods\n",
    "                    if \"private\" not in method_details.modifiers and not method_details.is_constructor:\n",
    "                        \n",
    "                        # Gather all the information needed for the prompt, which are focal method body, focal method name, focal class name, and constructor signature\n",
    "                        prompt = format_inst(\n",
    "                            focal_method_body=method_details.declaration+method_details.code,\n",
    "                            focal_method=method.split(\"(\")[0],\n",
    "                            focal_class=focal_class_name,\n",
    "                            constructor_signatures=constructor_signatures,\n",
    "                            language=\"java\"\n",
    "                        )\n",
    "                        \n",
    "                        # Print the instruction\n",
    "                        print(f\"Instruction:\\n{prompt}\\n\")\n",
    "                        print(f\"Generating test case ...\\n\")\n",
    "                        \n",
    "                        # Prompt the local model on Ollama\n",
    "                        llm_output = prompt_ollama(message=prompt)\n",
    "                        \n",
    "                        # Print the LLM output\n",
    "                        print(f\"LLM Output:\\n{llm_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
